{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load CSV Files\n",
    "content_path = \"Content (1).csv\"\n",
    "reaction_path = \"Reactions (1).csv\"\n",
    "reaction_types_path = \"ReactionTypes (1).csv\"\n",
    "\n",
    "content = pd.read_csv(content_path)\n",
    "reaction = pd.read_csv(reaction_path)\n",
    "reaction_types = pd.read_csv(reaction_types_path)\n",
    "\n",
    "# Step 3: Create SQLite Database and Load Data\n",
    "conn = sqlite3.connect('user_personas.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Content (\n",
    "    ContentID INTEGER,\n",
    "    UserID INTEGER,\n",
    "    Type TEXT,\n",
    "    Category TEXT,\n",
    "    URL TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS Reaction (\n",
    "    ContentID INTEGER,\n",
    "    UserID INTEGER,\n",
    "    Type TEXT,\n",
    "    Datetime TEXT\n",
    ");\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS ReactionTypes (\n",
    "    Type TEXT,\n",
    "    Sentiment TEXT,\n",
    "    Score INTEGER\n",
    ");\n",
    "''')\n",
    "\n",
    "# Load data into SQLite\n",
    "def load_to_sqlite(table_name, dataframe):\n",
    "    dataframe.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "load_to_sqlite(\"Content\", content)\n",
    "load_to_sqlite(\"Reaction\", reaction)\n",
    "load_to_sqlite(\"ReactionTypes\", reaction_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "content = content.drop_duplicates(subset=\"ContentID\")\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "content = content.dropna(subset=[\"ContentID\", \"Category\", \"Type\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_29604\\3183786796.py:8: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  reaction[\"Datetime\"] = pd.to_datetime(reaction[\"Datetime\"])\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "reaction = reaction.drop_duplicates()\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "reaction = reaction.dropna(subset=[\"ContentID\", \"Datetime\"])\n",
    "\n",
    "# Convert `Datetime` to datetime format\n",
    "reaction[\"Datetime\"] = pd.to_datetime(reaction[\"Datetime\"])\n",
    "\n",
    "# Filter rows where `ContentID` is not in `Content.csv`\n",
    "reaction = reaction[reaction[\"ContentID\"].isin(content[\"ContentID\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "reaction_types = reaction_types.drop_duplicates()\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "reaction_types = reaction_types.dropna(subset=[\"Type\", \"Sentiment\"])\n",
    "\n",
    "# Ensure sentiment values are consistent\n",
    "valid_sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "reaction_types = reaction_types[reaction_types[\"Sentiment\"].isin(valid_sentiments)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Categories by Popularity:\n",
      "          Category  TotalPopularity\n",
      "0         animals            69548\n",
      "1  healthy eating            69067\n",
      "2      technology            67472\n",
      "3         science            66043\n",
      "4         cooking            63982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Top 5 Categories by Popularity\n",
    "query_top_categories = \"\"\"\n",
    "SELECT \n",
    "    C.Category, \n",
    "    SUM(RT.Score) AS TotalPopularity\n",
    "FROM \n",
    "    Reaction R\n",
    "JOIN \n",
    "    Content C ON R.ContentID = C.ContentID\n",
    "JOIN \n",
    "    ReactionTypes RT ON R.Type = RT.Type\n",
    "GROUP BY \n",
    "    C.Category\n",
    "ORDER BY \n",
    "    TotalPopularity DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "df_top_categories = pd.read_sql(query_top_categories, conn)\n",
    "print(\"Top 5 Categories by Popularity:\\n\", df_top_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis by Category:\n",
      "       Category Sentiment  SentimentCount\n",
      "0    \"animals\"  negative              11\n",
      "1    \"animals\"   neutral               5\n",
      "2    \"animals\"  positive              24\n",
      "3    \"cooking\"  negative              10\n",
      "4    \"cooking\"   neutral               1\n",
      "..         ...       ...             ...\n",
      "110     travel   neutral             192\n",
      "111     travel  positive             904\n",
      "112   veganism  negative             372\n",
      "113   veganism   neutral             162\n",
      "114   veganism  positive             666\n",
      "\n",
      "[115 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2. Sentiment Analysis by Category\n",
    "query_sentiment_analysis = \"\"\"\n",
    "SELECT \n",
    "    C.Category, \n",
    "    RT.Sentiment, \n",
    "    COUNT(RT.Sentiment) AS SentimentCount\n",
    "FROM \n",
    "    Reaction R\n",
    "JOIN \n",
    "    Content C ON R.ContentID = C.ContentID\n",
    "JOIN \n",
    "    ReactionTypes RT ON R.Type = RT.Type\n",
    "GROUP BY \n",
    "    C.Category, RT.Sentiment;\n",
    "\"\"\"\n",
    "df_sentiment_analysis = pd.read_sql(query_sentiment_analysis, conn)\n",
    "print(\"Sentiment Analysis by Category:\\n\", df_sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type Analysis:\n",
      "            Category ContentType  TotalPopularity\n",
      "0           animals       photo            24464\n",
      "1        technology       audio            23160\n",
      "2           animals       audio            21628\n",
      "3         education       photo            20889\n",
      "4    healthy eating       audio            20712\n",
      "..              ...         ...              ...\n",
      "98   Healthy Eating       video              272\n",
      "99           Soccer         GIF              245\n",
      "100      Technology       video              217\n",
      "101       Education         GIF              152\n",
      "102          \"food\"       audio               50\n",
      "\n",
      "[103 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3. Content-Type Analysis\n",
    "query_content_type_analysis = \"\"\"\n",
    "SELECT \n",
    "    C.Category, \n",
    "    C.Type AS ContentType, \n",
    "    SUM(RT.Score) AS TotalPopularity\n",
    "FROM \n",
    "    Reaction R\n",
    "JOIN \n",
    "    Content C ON R.ContentID = C.ContentID\n",
    "JOIN \n",
    "    ReactionTypes RT ON R.Type = RT.Type\n",
    "GROUP BY \n",
    "    C.Category, C.Type\n",
    "ORDER BY \n",
    "    TotalPopularity DESC;\n",
    "\"\"\"\n",
    "df_content_type_analysis = pd.read_sql(query_content_type_analysis, conn)\n",
    "print(\"Content-Type Analysis:\\n\", df_content_type_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engagement Trends:\n",
      "   YearMonth  UniqueUsers  TotalReactions\n",
      "0      None          500           25553\n"
     ]
    }
   ],
   "source": [
    "# 4. Engagement Trends\n",
    "query_engagement_trends = \"\"\"\n",
    "SELECT \n",
    "    strftime('%Y-%m', R.Datetime) AS YearMonth, \n",
    "    COUNT(DISTINCT R.UserID) AS UniqueUsers, \n",
    "    COUNT(*) AS TotalReactions\n",
    "FROM \n",
    "    Reaction R\n",
    "GROUP BY \n",
    "    YearMonth\n",
    "ORDER BY \n",
    "    YearMonth;\n",
    "\"\"\"\n",
    "df_engagement_trends = pd.read_sql(query_engagement_trends, conn)\n",
    "print(\"Engagement Trends:\\n\", df_engagement_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Segmentation:\n",
      "                                    UserID  TotalReactions  TotalScore\n",
      "0                                    None            2039       80163\n",
      "1    c76c3393-88e2-47b0-ac37-dc4f2053f5a5              65        2757\n",
      "2    68724f58-bc4d-4ab0-a4e1-60cdd5e95e7d              65        2762\n",
      "3    0871bb31-3d6e-4e4c-ab19-95a262cac0d4              63        2287\n",
      "4    d1a89d23-7d17-4949-9e1a-637317141f3d              62        2820\n",
      "..                                    ...             ...         ...\n",
      "496  3663e3e6-3d5c-4ed9-a6af-1e680ec5f34b              31        1082\n",
      "497  e57c1d53-11ce-4df6-bb4b-85647776fd6d              30        1208\n",
      "498  b4a6b3ac-b6af-4525-8d59-7afc00ff279d              30         993\n",
      "499  90898216-e580-46c0-8e79-f2df84a9676d              30        1437\n",
      "500  a710ab29-b72a-42c8-a79b-42e63d4a8bfd              29        1124\n",
      "\n",
      "[501 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5. User Segmentation\n",
    "query_user_segmentation = \"\"\"\n",
    "SELECT \n",
    "    R.UserID, \n",
    "    COUNT(R.ContentID) AS TotalReactions, \n",
    "    SUM(RT.Score) AS TotalScore\n",
    "FROM \n",
    "    Reaction R\n",
    "JOIN \n",
    "    ReactionTypes RT ON R.Type = RT.Type\n",
    "GROUP BY \n",
    "    R.UserID\n",
    "ORDER BY \n",
    "    TotalReactions DESC;\n",
    "\"\"\"\n",
    "df_user_segmentation = pd.read_sql(query_user_segmentation, conn)\n",
    "print(\"User Segmentation:\\n\", df_user_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Aggregate Data with SQL Queries\n",
    "query = '''\n",
    "SELECT \n",
    "    r.UserID,\n",
    "    SUM(CASE WHEN rt.Sentiment = 'positive' THEN 1 ELSE 0 END) AS PositiveReactions,\n",
    "    SUM(CASE WHEN rt.Sentiment = 'negative' THEN 1 ELSE 0 END) AS NegativeReactions,\n",
    "    SUM(CASE WHEN rt.Sentiment = 'neutral' THEN 1 ELSE 0 END) AS NeutralReactions,\n",
    "    COUNT(r.ContentID) AS TotalReactions,\n",
    "    COUNT(DISTINCT DATE(r.Datetime)) AS ActiveDays\n",
    "FROM \n",
    "    Reaction r\n",
    "JOIN \n",
    "    ReactionTypes rt ON r.Type = rt.Type\n",
    "GROUP BY \n",
    "    r.UserID;\n",
    "'''\n",
    "\n",
    "user_reactions = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data saved to aggregatedreaction.csv\n",
      "User personas data saved to user_personas.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform SQL Queries for Aggregation\n",
    "query = \"\"\"\n",
    "WITH ReactionAggregated AS (\n",
    "    SELECT \n",
    "        r.ContentID,\n",
    "        c.Category,\n",
    "        rt.Sentiment,\n",
    "        SUM(rt.Score) AS PopularityScore\n",
    "    FROM Reaction r\n",
    "    JOIN Content c ON r.ContentID = c.ContentID\n",
    "    JOIN ReactionTypes rt ON r.Type = rt.Type\n",
    "    GROUP BY r.ContentID, c.Category, rt.Sentiment\n",
    ")\n",
    "SELECT \n",
    "    Category,\n",
    "    Sentiment,\n",
    "    SUM(PopularityScore) AS TotalPopularity\n",
    "FROM ReactionAggregated\n",
    "GROUP BY Category, Sentiment\n",
    "ORDER BY TotalPopularity DESC;\n",
    "\"\"\"\n",
    "\n",
    "aggregated_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Save the aggregated result to a CSV file\n",
    "aggregated_csv_file = \"aggregatedreaction.csv\"\n",
    "aggregated_df.to_csv(aggregated_csv_file, index=False)\n",
    "\n",
    "print(f\"Aggregated data saved to {aggregated_csv_file}\")\n",
    "\n",
    "# Step 5: Generate User Personas\n",
    "query_user_personas = \"\"\"\n",
    "WITH ReactionWithScores AS (\n",
    "    SELECT \n",
    "        r.UserID,\n",
    "        r.ContentID,\n",
    "        rt.Type AS ReactionType,\n",
    "        rt.Score\n",
    "    FROM Reaction r\n",
    "    JOIN ReactionTypes rt ON r.Type = rt.Type\n",
    "),\n",
    "UserEngagement AS (\n",
    "    SELECT \n",
    "        UserID,\n",
    "        COUNT(DISTINCT ContentID) AS TotalReactions,\n",
    "        AVG(Score) AS AvgReactionScore\n",
    "    FROM ReactionWithScores\n",
    "    GROUP BY UserID\n",
    ")\n",
    "SELECT \n",
    "    UserID,\n",
    "    TotalReactions,\n",
    "    AvgReactionScore,\n",
    "    CASE \n",
    "        WHEN TotalReactions > 50 THEN 'Highly Active'\n",
    "        WHEN TotalReactions BETWEEN 10 AND 50 THEN 'Moderately Active'\n",
    "        ELSE 'Occasional User'\n",
    "    END AS EngagementLevel\n",
    "FROM UserEngagement;\n",
    "\"\"\"\n",
    "\n",
    "user_personas_df = pd.read_sql_query(query_user_personas, conn)\n",
    "\n",
    "# Save user personas to a CSV file\n",
    "user_personas_csv_file = \"user_personas.csv\"\n",
    "user_personas_df.to_csv(user_personas_csv_file, index=False)\n",
    "\n",
    "print(f\"User personas data saved to {user_personas_csv_file}\")\n",
    "\n",
    "# Close the SQLite connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
